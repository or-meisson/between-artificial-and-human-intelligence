# between-artificial-and-human-intelligence
Exploring Self-Serving Bias in AI with Python and Hugging Face: A project that assesses the tendency of language models to attribute failures to external factors through a series of scenarios and benchmarks.

This repository contains the project "Between Artificial and Human Intelligence," which explores the presence of self-serving bias within AI language models. The project leverages Python and the Hugging Face platform to assess whether these models, demonstrate a tendency to attribute failures to external circumstances rather than their own decision-making processes. This research intendes for enhance our understanding of AI behavior in scenarios involving errors or unexpected outcomes. The repository includes the benchmark dataset, the Python scripts used for evaluation, and a detailed analysis of the findings. This work aims to contribute to the field of ethical AI by highlighting the importance of developing unbiased decision-making capabilities in artificial intelligence systems.
